{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install quickdraw\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT8rpP2mpVER",
        "outputId": "41223469-64ab-4293-8ff2-88adfc269fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: quickdraw in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from quickdraw) (9.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from quickdraw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (2023.11.17)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from quickdraw import QuickDrawDataGroup"
      ],
      "metadata": {
        "id": "75IQ48ueWJyc"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_d = 1001\n",
        "\n",
        "airplanes = QuickDrawDataGroup('airplane', max_drawings=max_d)\n",
        "castle = QuickDrawDataGroup('castle', max_drawings=max_d)\n",
        "dragon = QuickDrawDataGroup('dragon', max_drawings=max_d)\n",
        "duck = QuickDrawDataGroup('duck', max_drawings=max_d)\n",
        "fork = QuickDrawDataGroup('fork', max_drawings=max_d)\n",
        "hexagon = QuickDrawDataGroup('hexagon', max_drawings=max_d)\n",
        "key = QuickDrawDataGroup('key', max_drawings=max_d)\n",
        "mountain = QuickDrawDataGroup('mountain', max_drawings=max_d)\n",
        "pizza = QuickDrawDataGroup('pizza', max_drawings=max_d)\n",
        "star = QuickDrawDataGroup('star', max_drawings=max_d)\n",
        "sun = QuickDrawDataGroup('sun', max_drawings=max_d)\n",
        "tree = QuickDrawDataGroup('tree', max_drawings=max_d)\n",
        "\n",
        "# Define a class-to-number mapping\n",
        "class_mapping = {'airplane': 0, 'castle': 1, 'dragon': 2, 'duck': 3, 'fork': 4,\n",
        "                 'hexagon': 5, 'key': 6, 'mountain': 7, 'pizza': 8, 'star': 9, 'sun': 10, 'tree': 11}\n",
        "\n",
        "# Map class labels to numeric values\n",
        "img_classes = np.array([[class_mapping[drawing.name] for drawing in c.drawings] for c in [airplanes, castle, dragon, duck, fork,\n",
        "                                                                                          hexagon, key, mountain, pizza,\n",
        "                                                                                          star, sun, tree]]).flatten()[:-12]\n",
        "\n",
        "img_data = np.array([[np.array(drawing.get_image().resize((224, 224)).convert('L')) for drawing in c.drawings] for c in\n",
        "                     [airplanes, castle, dragon,\n",
        "                      duck, fork, hexagon,\n",
        "                      key, mountain,\n",
        "                      pizza, star,\n",
        "                      sun, tree]]\n",
        "                    )\n",
        "\n",
        "img_data = img_data.reshape((img_data.shape[0] * img_data.shape[1],) + img_data.shape[2:])\n",
        "print(\"Data loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRugDqDKWfMn",
        "outputId": "e1360ef5-3e96-4c0c-eec4-12b8c5d469b1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading airplane drawings\n",
            "load complete\n",
            "loading castle drawings\n",
            "load complete\n",
            "loading dragon drawings\n",
            "load complete\n",
            "loading duck drawings\n",
            "load complete\n",
            "loading fork drawings\n",
            "load complete\n",
            "loading hexagon drawings\n",
            "load complete\n",
            "loading key drawings\n",
            "load complete\n",
            "loading mountain drawings\n",
            "load complete\n",
            "loading pizza drawings\n",
            "load complete\n",
            "loading star drawings\n",
            "load complete\n",
            "loading sun drawings\n",
            "load complete\n",
            "loading tree drawings\n",
            "load complete\n",
            "Data loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_classes.shape)\n",
        "print(img_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKyJPD9gBc-q",
        "outputId": "c86cc44b-109c-4c31-d747-9fde1140e568"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12000,)\n",
            "(12000, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    img_data,\n",
        "    img_classes,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "Q4nknIciWqoL"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gia7rnydoFif",
        "outputId": "6bc0acd6-a186-47ad-f65d-8b2c7c4c90b9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9600, 224, 224) (2400, 224, 224) (9600,) (2400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension of size 3 to each array\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_train = np.repeat(x_train, 3, axis=-1)\n",
        "\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "x_test = np.repeat(x_test, 3, axis=-1)\n",
        "\n",
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "y_train = np.repeat(y_train, 3, axis=-1)\n",
        "\n",
        "y_test = np.expand_dims(y_test, axis=-1)\n",
        "y_test = np.repeat(y_test, 3, axis=-1)\n",
        "\n",
        "print(\"Updated shapes:\")\n",
        "print(\"x_train:\", x_train.shape)\n",
        "print(\"x_test:\", x_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPGp5XzRQ7iT",
        "outputId": "adef61f6-df2e-4683-e9f0-01d49acaf5bd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated shapes:\n",
            "x_train: (9600, 224, 224, 3)\n",
            "x_test: (2400, 224, 224, 3)\n",
            "y_train: (9600, 3)\n",
            "y_test: (2400, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "bLlhFsMXRGDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2267ad5c-0ce8-44ea-e249-626c701ba182"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9600, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Assuming x_train, y_train, x_test, and y_test are your datasets\n",
        "# If the shapes are different, you might need to adjust the model accordingly\n",
        "\n",
        "# Load VGG19 model without top layers\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom top layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(12, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "jjvndVJVoy3a"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY0usy3Uzs-I",
        "outputId": "c31d9241-d289-4e76-c43d-d39b0788d50c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9600, 224, 224, 3) (2400, 224, 224, 3) (9600, 3) (2400, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "k5H-34WkuSxX",
        "outputId": "33e384ae-c82c-4dd4-c429-d55003e03325"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-ae15a897eb73>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5777, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(96,) and logits.shape=(32, 12)\n"
          ]
        }
      ]
    }
  ]
}